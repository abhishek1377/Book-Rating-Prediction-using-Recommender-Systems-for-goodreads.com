{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fskSSiOmzWbd",
    "outputId": "01ea87e2-c6c7-442b-8bd1-c8f0feaad03d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_bO_6iRzyyw"
   },
   "outputs": [],
   "source": [
    "!cd /content/drive/MyDrive/6240_project/project_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "n-YgyCY90Bml"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jY0QlFG6zcyS"
   },
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    count = 0\n",
    "    data = []\n",
    "    with gzip.open(file_name) as fin:\n",
    "        for l in fin:\n",
    "            d = json.loads(l)\n",
    "            count += 1\n",
    "            data.append(d)\n",
    "            \n",
    "          \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4s7VNmob0Cuu"
   },
   "outputs": [],
   "source": [
    "interactions = load_data('datasets/goodreads_interactions_poetry.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CBYSgjom0NQE"
   },
   "outputs": [],
   "source": [
    "interactions_df = pd.json_normalize(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ve4-I-RC2b6B",
    "outputId": "b8fd181c-0d7f-473e-c228-2c48518fbad3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2734350"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(interactions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vDo81cfZ0YEv"
   },
   "outputs": [],
   "source": [
    "user_map = pd.read_csv('datasets/user_id_map.csv')\n",
    "book_map = pd.read_csv('datasets/book_id_map.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9m1jQwtZ1hQn"
   },
   "outputs": [],
   "source": [
    "rating_df = interactions_df.merge(user_map,on='user_id')[['user_id_csv','book_id','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "ipeRp_vOZxs4",
    "outputId": "d09a72f0-47c1-4310-fae4-f2e8b2305ea4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_csv</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1384</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1376</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>30119</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30119</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>240007</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229054</th>\n",
       "      <td>876132</td>\n",
       "      <td>2547</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229055</th>\n",
       "      <td>876133</td>\n",
       "      <td>11047097</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229056</th>\n",
       "      <td>876144</td>\n",
       "      <td>7433930</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229057</th>\n",
       "      <td>876144</td>\n",
       "      <td>16170625</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229058</th>\n",
       "      <td>876144</td>\n",
       "      <td>16101638</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1229059 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id_csv   book_id  rating\n",
       "0                  0      1384       4\n",
       "1                  0      1376       4\n",
       "2                  0     30119       5\n",
       "3                  1     30119       3\n",
       "4                  2    240007       4\n",
       "...              ...       ...     ...\n",
       "1229054       876132      2547       5\n",
       "1229055       876133  11047097       4\n",
       "1229056       876144   7433930       5\n",
       "1229057       876144  16170625       5\n",
       "1229058       876144  16101638       4\n",
       "\n",
       "[1229059 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero = rating_df[rating_df['rating']!=0].reset_index(drop=True)\n",
    "non_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero.to_csv(\"user_item_ratings.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IST7lNj76Sa8"
   },
   "outputs": [],
   "source": [
    "def preprocessing(training_data):\n",
    "  \"\"\"\n",
    "  Arguments:\n",
    "  training data (str-type numpy.array): the training data containing user_id, movie_id, and normalized rating (0-1) information.\n",
    "\n",
    "  Returns:\n",
    "  R_ui (dictionary of dictionaries): this dictionary contains rating information of each user. \n",
    "   - The key is user_id (string), the value is a dictionary whose key is item_id (string) and value is rating (float).\n",
    "   - Thus, R_ui['1']['260'] = 1.0. R_ui should be computed with training data.\n",
    "  R_iu (dictionary of dictionaries): it is similar to R_ui, but the key of a dictionary is item_id (string). \n",
    "   - Thus, R_ui['260']['1'] = 1.0. R_iu should be computed with training data.\n",
    "\n",
    "  Steps:\n",
    "  1. for each training example with (user u, item i, and rating r), R_ui[u][i] should be r (float). R_iu can be computed similarly.\n",
    "  \"\"\"\n",
    "  R_ui,R_iu = defaultdict(dict),defaultdict(dict)\n",
    "\n",
    "  ## Add code below [0.5 points] ##\n",
    "\n",
    "  for index in tqdm(range(len(training_data)),desc=\"Complete...\"):\n",
    "    \n",
    "    u_id = str(training_data.loc[index]['user_id_csv'])\n",
    "    it_id = str(training_data.loc[index]['book_id'])\n",
    "    r = float(training_data.loc[index]['rating'])\n",
    "\n",
    "    R_ui[u_id][it_id] = r\n",
    "    R_iu[it_id][u_id] = r\n",
    "\n",
    "  \n",
    "  #################################\n",
    "  return R_ui,R_iu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5gHE8Ymy9kpi",
    "outputId": "db793b3d-3568-496e-8146-539b43f5bb9e"
   },
   "outputs": [],
   "source": [
    "# R_ui,R_iu = preprocessing(non_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KJ7sqzcOIpu9",
    "outputId": "6f92ca08-17f3-49eb-eb3b-137607fcc24b"
   },
   "outputs": [],
   "source": [
    "# print('R_ui of user 0 and item 1384 = {}'.format(R_ui[\"0\"]['1384']))\n",
    "# print('R_iu of user 30119 and item 1 = {}'.format(R_iu['30119']['1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfUQ-hbD-259"
   },
   "outputs": [],
   "source": [
    "def gradient_descent_update(U,V,K):\n",
    "  \"\"\"\n",
    "  Do not modify this function. There is a -2.0 point penalty if you modify this function.\n",
    "\n",
    "  Arguments: \n",
    "  U,V (dictionary of numpy.array): current user and item profile dictionaries. \n",
    "   - The key is either user_id or item_id, and the value is the corresponding user or item profile (numpy.array; dim:K).\n",
    "  K (int): the number of latent factors.\n",
    "\n",
    "  Returns:\n",
    "  Updated U,V (dictionary of numpy.array): updated user and item profile dictionaries. \n",
    "   - The key is either user_id or item_id, and the value is the corresponding user or item profile (numpy.array; dim:K).\n",
    "  \"\"\"\n",
    "  mu = 0.00001\n",
    "  lambda_value = 0.00001\n",
    "  for user in U.keys():\n",
    "    updates = np.zeros(K)\n",
    "    for item in R_ui[user].keys():\n",
    "      pred = np.inner(U[user],V[item])\n",
    "      error = R_ui[user][item] - pred\n",
    "      updates += error*V[item]\n",
    "    final_updates = 2*mu*updates - 2*lambda_value*U[user]\n",
    "    U[user] += final_updates\n",
    "\n",
    "  for item in V.keys():\n",
    "    updates = np.zeros(K)\n",
    "    for user in R_iu[item].keys():\n",
    "      pred = np.inner(U[user],V[item])\n",
    "      error = R_iu[item][user] - pred\n",
    "      updates += error*U[user]\n",
    "    final_updates = 2*mu*updates - 2*lambda_value*V[item]\n",
    "    V[item] += final_updates\n",
    "  return U,V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zb7MzdTe-3Ds"
   },
   "outputs": [],
   "source": [
    "def matrix_factorization (training_data, K=15, epochs = 100):\n",
    "  \"\"\"\n",
    "  Arguments:\n",
    "  training data (str-type numpy.array): the training data containing user_id, movie_id, and normalized rating (0-1) information.\n",
    "  K (int): number of latent factors used for matrix factorization.\n",
    "  epochs (int): number of repetitions of the updates of U and V.\n",
    "\n",
    "  Returns:\n",
    "  U,V (dictionary of float-type numpy.array): learned user and item profile dictionaries. \n",
    "   - The key is either user_id or item_id, and the value is the corresponding user or item profile (float-type numpy.array; dim:K).\n",
    "\n",
    "  Steps for the first code block:\n",
    "  1. compute the maximum value using 'sqrt(avg(ratings of all training examples)/K)' for the initialization (ratings of all training examples should be float-type, not str-type here).\n",
    "  2. for each user u in training_data, initialize the value of U[u] with a size-K numpy.array (float) filled with random values between 0 the maximum value.\n",
    "  3. initialize V[v] for each item v in training_data like step 2.\n",
    "      - when you assign the initial value, please use R_ui.keys(), R_iu.keys() to keep the order and to avoid multiple initialization.\n",
    "  \"\"\"\n",
    "\n",
    "  np.random.seed(0)\n",
    "  U,V = defaultdict(np.array),defaultdict(np.array)\n",
    "\n",
    "  ## Add code below [1.0 points] ##\n",
    "\n",
    "  avg_rating = np.mean(training_data[:,2].astype(float))\n",
    "\n",
    "  max_value = (avg_rating/K)**0.5\n",
    "\n",
    "  users = list(R_ui.keys())\n",
    "  items = list(R_iu.keys())\n",
    "\n",
    "  for user in users:\n",
    "    U[user] = np.random.uniform(low=0,high=max_value,size=K).astype(float)\n",
    "\n",
    "  for item in items:\n",
    "    V[item] = np.random.uniform(low=0,high=max_value,size=K).astype(float)\n",
    "\n",
    "  #################################\n",
    "\n",
    "  \"\"\"\n",
    "  Steps for the second code block:\n",
    "  1. for each iteration, call the gradient_descent_update with current U and V.\n",
    "  2. update the user and item profile matrices with the returned U and V.\n",
    "  \"\"\"\n",
    "  ## Add code below [1.0 points] ##\n",
    "\n",
    "  for j in tqdm(range(epochs),desc='Completed......'):\n",
    "    U,V = gradient_descent_update(U,V,K)\n",
    "\n",
    "  #################################\n",
    "  return U,V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8URYHcCAXejv"
   },
   "outputs": [],
   "source": [
    "# with open('user_dict.pickle', 'wb') as handle:\n",
    "#     pickle.dump(R_ui, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('item_dict.pickle', 'wb') as handle:\n",
    "#     pickle.dump(R_iu, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AzByEoTq_fUO"
   },
   "outputs": [],
   "source": [
    "training_data = np.array(non_zero,dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6rQFOuom_NFU",
    "outputId": "9e07a6e0-d105-4213-bb74-e557bf1491c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Completed......: 100%|██████████| 100/100 [35:30<00:00, 21.30s/it]\n"
     ]
    }
   ],
   "source": [
    "(W,H) = matrix_factorization(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-0hWRcLmI_VZ"
   },
   "outputs": [],
   "source": [
    "with open('user1.pickle', 'wb') as handle:\n",
    "    pickle.dump(W, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EV7h4JmnJji2"
   },
   "outputs": [],
   "source": [
    "with open('item1.pickle', 'wb') as handle:\n",
    "    pickle.dump(H, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
} 
